{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Classification (14 points):\n",
    "Each item worth 2 points, except item 6 which is worth 4 points.\n",
    "\n",
    "For each question that asks to implement a function, implement it in the top cell where it is defined and then execute the function in the code cell provided below the question. <br>\n",
    "You should base your answers on the output.<br>\n",
    "You are allowed to implement and use additional functions. These would be defined and implemented in the\n",
    "cell directly below the questions they were implemented for.\n",
    "\n",
    "All the textual answers should be based on and justified with output from the data in the code cell above.<br>\n",
    "For example, if the question asks about the correlation value, the code calculating it should appear above the answer, and the value should be in the output.\n",
    "The answers should be concise and written in your own words.\n",
    "\n",
    "\n",
    "### <span style=\"color:red\">Do Not Modify the Structure of this Notebook, don't add/remove/move cells or change their type (Code/Markdown) </span>\n",
    "\n",
    "1. [Read the feather file 'TrainQuestionsDF.feather.zstd' into a pandas dataframe. <br>Use the function train_test_split to split the data into two sets, 75% for training and 25% for validation. <br> Generate stratified samples with the *random_state=RANDOM_SEED*.](#q1)\n",
    "<br><br>\n",
    "2. [Implement the function `fit_tree_classifier(X, y)`, then use it to fit a decision tree classifier on the train dataset and generate prediction for the validation data set. <br>Use only the numerical columns as features (you can use the function from DataExploration).](#q2)\n",
    "<br><br>\n",
    "3. [Implement the function `evaluate_classification(y_true, y_predicted)`, then use it to evaluate the classification made by the decision tree classifier on the validation dataset.](#q3)\n",
    "<br><br>\n",
    "4. [Implement the function `fit_knn_classifier(X, y)` and use it to fit the model on the train data and then generate prediction for the validation data. Using the previous evaluation.](#q4)\n",
    "<br><br>\n",
    "5. [Now we turn to a different features set, we will utilize the text in the Title field of each sample to generate a features vector for the sample. <br> You should apply the TfidfVectorizer to generate tf-idf (term frequency-inverse document frequency) features from the text in the Title field of each sample. <br>Make sure to use the same vocabulary for both the training set and the validation. The vocabulary size determines the vector size, each entry in the vector represents the tf-idf value for the corresponding term. <br> Implement the function `series_to_tfidf(sr)`, then generate tf-idf vectors for the training and validation sets and train two classifiers (decision tree and knn) using the generated vectors.](#q5)\n",
    "<br><br>\n",
    "6. [Using the documentation for the two classification and the text feature extraction models and their different parameters. <br>Find a combination of parameters that improves the accuracy for each model, and for at least one of the models the improvement should be by at least 5% on the validation dataset. <br>Write your code below and describe the changes you made and the intuition behind them. <br>For applying a systematic search, i.e. not just manually checking for different parameters.](#q6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Set the random seed as your student id (only numbers)\n",
    "RANDOM_SEED = 3955778\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for functions given to you to use\n",
    "def read_feather_to_df(feather_file_name):\n",
    "    \"\"\"\n",
    "    The function expects to receive a path to feather file,\n",
    "    it will read the file from the disk into a pandas dataframe\n",
    "    :param feather_file_name: a string or path like object\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "    return pd.read_feather(feather_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for all the functions you are expected to implement.\n",
    "# You should implement them here and only call them below when they are mentioned in a question.\n",
    "\n",
    "def select_numeric_non_id_columns(df):\n",
    "    \"\"\"\n",
    "    Return a subset of a DataFrameâ€™s columns based on the column dtypes,\n",
    "    including only numerical columns and excluding columns with the string id (case-insensitive) in their name\n",
    "    :param df: pd.DataFrame\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "    Z = (df.select_dtypes(include=['int64', 'object'], exclude=[\"string\", \"datetime64\"])).drop('Id',axis=1)\n",
    "    \n",
    "    return Z\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def fit_tree_classifier(X, y): \n",
    "    \"\"\"\n",
    "    The function receives a multidimensional array or a dataframe of features as X and one dimensional array or pandas Series as y.\n",
    "    It creates a DecisionTreeClassifier classifier with random_state=RANDOM_SEED, fits it on X and y and returns the fitted classifier.\n",
    "    :param X: ndarray, pd.DataFrame or a sparse matrix; data features\n",
    "    :param y: array-like; data class labels\n",
    "    :param decisiontree_kwargs: key-word arguments that will be passed to DecisionTreeClassifier class\n",
    "    :return: a fitted DecisionTreeClassifier object\n",
    "    \"\"\"\n",
    "    dt_classifier = DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "    dt_classifier.fit(X, y)\n",
    "    \n",
    "    \n",
    "    return\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def fit_knn_classifier(X, y, **knn_kwargs):\n",
    "    \"\"\"\n",
    "    The function receives a multidimensional array or a dataframe of features as X, on dimensional array or pandas Series as y.\n",
    "    It creates a DecisionTreeClassifier classifier with random_state=RANDOM_SEED, fits it on X and y and returns the fitted classifier.\n",
    "    :param X: ndarray, pd.DataFrame or a sparse matrix; data features\n",
    "    :param y: array-like; data class labels\n",
    "    :param knn_kwargs: key-word arguments that will be passed to KNeighborsClassifier class\n",
    "    :return: a fitted KNeighborsClassifier object\n",
    "    \"\"\"\n",
    "    knn_clf = KNeighborsClassifier()\n",
    "    \n",
    "    knn_clf.fit(X, y,)\n",
    "    \n",
    "    return knn_clf\n",
    "    \n",
    "    pass\n",
    "\n",
    "def evaluate_classification(y_true, y_predicted):\n",
    "    \"\"\"\n",
    "    The function receives two arrays or pandas Series with the same length, the actual labels and the predicted labels.\n",
    "    It then prints the sklearn classification_report and plots a confusion matrix as a heatmap using the class ConfusionMatrixDisplay.\n",
    "    The plot should be readable (e.g. not overlapping labels or too small text)\n",
    "    :param y_true: array-like; ground truth data class labels\n",
    "    :param y_predicted: array-like; predicted data class labels\n",
    "    \"\"\"\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def series_to_tfidf(sr, **tfidfvectorizer_kwargs):\n",
    "    \"\"\"\n",
    "    The function receives an array or a pandas Series that contains text strings (a.k.a documents).\n",
    "    It then converts the documents into a matrix of TF-IDF features\n",
    "    The function should return two objects:\n",
    "    TfidfVectorizer object after it learned (fitted) the vocabulary and idf from the training set,\n",
    "    and a document-term matrix (the original documents array transformed into a TF-IDF features matrix).\n",
    "    :param sr: pd.Series, contains text strings\n",
    "    :param tfidfvectorizer_kwargs: key-word arguments that will be passed to TfidfVectorizer class\n",
    "    :return: two objects, the fitted TfidfVectorizer object and the tf-idf document-term sparse matrix\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    sr = vectorizer.fit_transform(sr).getnnz()\n",
    "    vectorizer.get_feature_names_out()\n",
    "    \n",
    "    return \n",
    "\n",
    "#Hyperparameter evaluation suite. This code will automatically search for the optimal set of parameters for  \n",
    "\n",
    "cv_method = RepeatedStratifiedKFold(n_splits=5, \n",
    "                                    n_repeats=3, \n",
    "                                    random_state=RANDOM_SEED)\n",
    "\n",
    "df_classifier = DecisionTreeClassifier(random_state=RANDOM_SEED)\n",
    "\n",
    "\n",
    "params_DT = {'criterion': ['gini', 'entropy'],\n",
    "             'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20],\n",
    "             'min_samples_split': [2, 3, 5, 10]}\n",
    "\n",
    "gs_DT = GridSearchCV(estimator=df_classifier, \n",
    "                     param_grid=params_DT, \n",
    "                     cv=cv_method,\n",
    "                     verbose=1, \n",
    "                     scoring='accuracy')\n",
    "\n",
    "params_KNN = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7], \n",
    "              'p': [1, 2]}\n",
    "\n",
    "gs_KNN = GridSearchCV(estimator=KNeighborsClassifier(), \n",
    "                      param_grid=params_KNN, \n",
    "                      cv=cv_method,\n",
    "                      verbose=1, \n",
    "                      scoring='accuracy', \n",
    "                      return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <a name=\"q1\"></a> 1. Read the feather file 'TrainQuestionsDF.feather.zstd' into a pandas dataframe. <br>Use the function [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split the data into two sets, 75% for training and 25% for validation. <br> Generate stratified samples with the **random_state=RANDOM_SEED**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df = read_feather_to_df('TrainQuestionsDF.feather.zstd')\n",
    "\n",
    "X = train_df.iloc[:, :-1]\n",
    "y = train_df.iloc[:, -1]\n",
    "\n",
    "num_df = select_numeric_non_id_columns(train_df)\n",
    "\n",
    "num_X = num_df.iloc[:, :-1]\n",
    "num_y = num_df.iloc[:, -1]\n",
    "\n",
    "\n",
    "num_X_train, num_X_test, num_y_train, num_y_test = train_test_split(num_X, num_y ,test_size=0.25, random_state=RANDOM_SEED)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.25, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <a name=\"q2\"></a> 2. Implement the function `fit_tree_classifier(X, y, **decisiontree_kwargs)`, then use it to fit a decision tree classifier on the train dataset and generate prediction for the validation data set. Make sure to set **random_state=RANDOM_SEED** within the function. <br>Use only the numerical columns as features and print the labels of the first 5 predictions (you can use the function from DataExploration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time-series' 'bayesian' 'logistic' 'time-series' 'hypothesis-testing']\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state=RANDOM_SEED)\n",
    "dt_classifier.fit(num_X_train, num_y_train)\n",
    "\n",
    "y_pred = dt_classifier.predict(num_X_test)\n",
    "print(y_pred[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <a name=\"q3\"></a> 3. Implement the function `evaluate_classification(y_true, y_predicted)`, then use it to evaluate the classification made by the decision tree classifier on the validation dataset.<br>3.1 For which label did the model achieve the best result, and how many samples were classified correctly for that label? <br>3.2 How many samples with the label 'bayesian' were classified as 'time-series'? <br>3.3 Was the model successful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          bayesian       0.18      0.18      0.18       718\n",
      "     distributions       0.13      0.14      0.13       747\n",
      "hypothesis-testing       0.16      0.16      0.16       768\n",
      "          logistic       0.17      0.17      0.17       747\n",
      "       probability       0.16      0.17      0.16       753\n",
      "        self-study       0.21      0.20      0.21       764\n",
      "       time-series       0.18      0.17      0.17       756\n",
      "\n",
      "          accuracy                           0.17      5253\n",
      "         macro avg       0.17      0.17      0.17      5253\n",
      "      weighted avg       0.17      0.17      0.17      5253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_classification(num_y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* 3.1 The self study label appears to have enjoyed the most success with 214 samples labeled correctly (29% of 764).\n",
    "* 3.2 143 or 20% of 718\n",
    "* 3.3 This model was not successful, an accuracy of 20% is very low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <a name=\"q4\"></a> 4. Implement the function `fit_knn_classifier(X, y)` and use it to fit the model on the train data and then generate prediction for the validation data. Using the previous evaluation answer the following questions: <br>4.1 Which model achieved higher accuracy on the validation set? <br>4.2 Can you identify a bias towards a certain class in the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          bayesian       0.18      0.18      0.18       718\n",
      "     distributions       0.13      0.14      0.13       747\n",
      "hypothesis-testing       0.16      0.16      0.16       768\n",
      "          logistic       0.17      0.17      0.17       747\n",
      "       probability       0.16      0.17      0.16       753\n",
      "        self-study       0.21      0.20      0.21       764\n",
      "       time-series       0.18      0.17      0.17       756\n",
      "\n",
      "          accuracy                           0.17      5253\n",
      "         macro avg       0.17      0.17      0.17      5253\n",
      "      weighted avg       0.17      0.17      0.17      5253\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(num_X_train, num_y_train)\n",
    "\n",
    "k_pred = knn_classifier.predict(num_X_test)\n",
    "\n",
    "print(evaluate_classification(num_y_test, k_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* 4.1 The DT model achieved a better accuracy, but only by 3%\n",
    "* 4.2 The lable 'Self study' appears to achieve better results in both models, but it's still not great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <a name=\"q5\"></a> 5. Now we turn to a different features set, we will utilize the text in the Title field of each sample to generate a features vector for the sample. <br> You should apply the [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) to generate tf-idf (term frequency-inverse document frequency) features from the text in the Title field of each sample. <br>Make sure to use the same vocabulary for both the training set and the validation. The vocabulary size determines the vector size, each entry in the vector represents the tf-idf value for the corresponding term. <br> Implement the function `series_to_tfidf(sr, **tfidfvectorizer_kwargs)`, then generate tf-idf vectors for the training and validation sets and train two classifiers (decision tree and knn) using the generated vectors. Answer the following questions:<br>5.1 Which model achieves higher accuracy on the validation set? <br>5.2 For each model specify the label it gets most correct and most incorrect prediction for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          bayesian       0.18      0.18      0.18       718\n",
      "     distributions       0.13      0.14      0.13       747\n",
      "hypothesis-testing       0.16      0.16      0.16       768\n",
      "          logistic       0.17      0.17      0.17       747\n",
      "       probability       0.16      0.17      0.16       753\n",
      "        self-study       0.21      0.20      0.21       764\n",
      "       time-series       0.18      0.17      0.17       756\n",
      "\n",
      "          accuracy                           0.17      5253\n",
      "         macro avg       0.17      0.17      0.17      5253\n",
      "      weighted avg       0.17      0.17      0.17      5253\n",
      "\n",
      "None\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          bayesian       0.18      0.18      0.18       718\n",
      "     distributions       0.13      0.14      0.13       747\n",
      "hypothesis-testing       0.16      0.16      0.16       768\n",
      "          logistic       0.17      0.17      0.17       747\n",
      "       probability       0.16      0.17      0.16       753\n",
      "        self-study       0.21      0.20      0.21       764\n",
      "       time-series       0.18      0.17      0.17       756\n",
      "\n",
      "          accuracy                           0.17      5253\n",
      "         macro avg       0.17      0.17      0.17      5253\n",
      "      weighted avg       0.17      0.17      0.17      5253\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train['Title'] = vectorizer.fit_transform(X_train['Title']).getnnz()\n",
    "X_test['Title'] = vectorizer.fit_transform(X_test['Title']).getnnz()\n",
    "\n",
    "vectorizer.get_feature_names_out()\n",
    "vectorizer.get_feature_names_out()\n",
    "\n",
    "vect_X_train = select_numeric_non_id_columns(X_train)\n",
    "vect_X_test = select_numeric_non_id_columns(X_test)\n",
    "\n",
    "#knn classifier\n",
    "knn_classifier.fit(vect_X_train, num_y_train)\n",
    "\n",
    "vk_pred = knn_classifier.predict(vect_X_test)\n",
    "\n",
    "print(evaluate_classification(num_y_test, vk_pred))\n",
    "\n",
    "#DT Classifier\n",
    "dt_classifier.fit(vect_X_train, num_y_train)\n",
    "\n",
    "vy_pred = knn_classifier.predict(vect_X_test)\n",
    "\n",
    "print(evaluate_classification(num_y_test, vy_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* 5.1 Neither, they both achieve the same results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <a name=\"q6\"></a> 6. Using the documentation for the two classification and the text feature extraction models and their different parameters. <br>Find a combination of parameters that improves the accuracy for each model, and for at least one of the models the improvement should be by at least 5% on the validation dataset. <br>Write your code below and describe the changes you made and the intuition behind them. <br>1 point will be awarded for applying a systematic search, i.e. not just manually checking different values for different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 96 candidates, totalling 1440 fits\n",
      " Optimal parameters for this algorithm are {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 2}\n",
      " Top accuracy score with optimal parameters is 0.2055039801507968\n",
      "Fitting 15 folds for each of 14 candidates, totalling 210 fits\n",
      " Optimal parameters for this algorithm are {'n_neighbors': 1, 'p': 1}\n",
      " Top accuracy score with optimal parameters is 0.19790995768002104\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          bayesian       0.18      0.18      0.18       718\n",
      "     distributions       0.13      0.14      0.13       747\n",
      "hypothesis-testing       0.16      0.16      0.16       768\n",
      "          logistic       0.17      0.17      0.17       747\n",
      "       probability       0.16      0.17      0.16       753\n",
      "        self-study       0.21      0.20      0.21       764\n",
      "       time-series       0.18      0.17      0.17       756\n",
      "\n",
      "          accuracy                           0.17      5253\n",
      "         macro avg       0.17      0.17      0.17      5253\n",
      "      weighted avg       0.17      0.17      0.17      5253\n",
      "\n",
      "None\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          bayesian       0.18      0.18      0.18       718\n",
      "     distributions       0.13      0.14      0.13       747\n",
      "hypothesis-testing       0.16      0.16      0.16       768\n",
      "          logistic       0.17      0.17      0.17       747\n",
      "       probability       0.16      0.17      0.16       753\n",
      "        self-study       0.21      0.20      0.21       764\n",
      "       time-series       0.18      0.17      0.17       756\n",
      "\n",
      "          accuracy                           0.17      5253\n",
      "         macro avg       0.17      0.17      0.17      5253\n",
      "      weighted avg       0.17      0.17      0.17      5253\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "gs_DT.fit(vect_X_train, num_y_train);\n",
    "\n",
    "print(f\" Optimal parameters for this algorithm are {gs_DT.best_params_}\")\n",
    "print(f\" Top accuracy score with optimal parameters is {gs_DT.best_score_}\")\n",
    "\n",
    "\n",
    "\n",
    "gs_KNN.fit(vect_X_train, num_y_train);\n",
    "\n",
    "print(f\" Optimal parameters for this algorithm are {gs_KNN.best_params_}\")\n",
    "print(f\" Top accuracy score with optimal parameters is {gs_KNN.best_score_}\")\n",
    "\n",
    "#Training model with optimal params\n",
    "\n",
    "dt_classifier_optimal = DecisionTreeClassifier(criterion='gini', max_depth=7, min_samples_split=2, random_state=RANDOM_SEED)\n",
    "dt_classifier_optimal.fit(vect_X_train, num_y_train)\n",
    "\n",
    "opt_pred = dt_classifier.predict(vect_X_test)\n",
    "print(evaluate_classification(y_test, opt_pred))\n",
    "\n",
    "knn_classifier_optimal = KNeighborsClassifier(n_neighbors=1, p=1)\n",
    "knn_classifier.fit(vect_X_train, num_y_train)\n",
    "\n",
    "opt_k_pred = knn_classifier.predict(vect_X_test)\n",
    "\n",
    "print(evaluate_classification(y_test, opt_k_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In order to achieve the results above I utilised a Repeated Stratified KFold cross validation method, within the grid search function, to to train my model using multiple variations of each algorithm's hyperparameters. This method returns the optimal parameters for both decision trees and K nearest neighbors. \n",
    "\n",
    "Even with this sophisticated set up I was unable to affect any change in the accuracy of the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
