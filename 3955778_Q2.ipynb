{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99c076df",
   "metadata": {},
   "source": [
    "# MATH2319/ MATH2387 Machine Learning\n",
    "## Take-Home Assessment\n",
    "### Galen Ralph Herten-Crabb 3955778 \n",
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a4f1d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import requests\n",
    "import math\n",
    "import statistics\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ea2cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"THA_diamonds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04398e9c",
   "metadata": {},
   "source": [
    "### Part A\n",
    "Discretize the depth and carat features separately as \"category_1\", \"category_2\", and \"category_3\" respectively using the equal-frequency binning technique.\n",
    "\n",
    "To achieve this the qcut function was called, separating each variable into the categories specified. This process creates three evenly distributed categories or levels for further calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5c39d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()\n",
    "df2['depth'] = pd.qcut(df2['depth'], \n",
    "                              q=3, \n",
    "                              labels=['category_1', 'category_2', 'category_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6b92226",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['carat'] = pd.qcut(df2['carat'], \n",
    "                              q=3, \n",
    "                              labels=['category_1', 'category_2', 'category_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37be0d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>depth</th>\n",
       "      <th>price</th>\n",
       "      <th>carat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>category_2</td>\n",
       "      <td>low</td>\n",
       "      <td>category_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fair</td>\n",
       "      <td>F</td>\n",
       "      <td>category_3</td>\n",
       "      <td>low</td>\n",
       "      <td>category_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>I</td>\n",
       "      <td>category_1</td>\n",
       "      <td>low</td>\n",
       "      <td>category_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>F</td>\n",
       "      <td>category_1</td>\n",
       "      <td>low</td>\n",
       "      <td>category_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fair</td>\n",
       "      <td>F</td>\n",
       "      <td>category_3</td>\n",
       "      <td>low</td>\n",
       "      <td>category_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fair</td>\n",
       "      <td>F</td>\n",
       "      <td>category_3</td>\n",
       "      <td>low</td>\n",
       "      <td>category_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>category_2</td>\n",
       "      <td>low</td>\n",
       "      <td>category_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>category_2</td>\n",
       "      <td>low</td>\n",
       "      <td>category_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>category_2</td>\n",
       "      <td>low</td>\n",
       "      <td>category_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fair</td>\n",
       "      <td>F</td>\n",
       "      <td>category_3</td>\n",
       "      <td>low</td>\n",
       "      <td>category_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cut color       depth price       carat\n",
       "0  Good     D  category_2   low  category_1\n",
       "1  Fair     F  category_3   low  category_1\n",
       "2  Good     I  category_1   low  category_1\n",
       "3  Good     F  category_1   low  category_1\n",
       "4  Fair     F  category_3   low  category_1\n",
       "5  Fair     F  category_3   low  category_1\n",
       "6  Good     D  category_2   low  category_1\n",
       "7  Good     D  category_2   low  category_1\n",
       "8  Good     D  category_2   low  category_1\n",
       "9  Fair     F  category_3   low  category_1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309465d",
   "metadata": {},
   "source": [
    "### Part B\n",
    "Compute the impurity of the price feature\n",
    "\n",
    "Value_counts function is called to determine the frequency of values within the price variable, these frequencies also amount to the probability of each level. The result is passed through the purity using entropy formula.\n",
    "\n",
    "To make things easier later the 'compute_impurity' function from the course website is written in and tested to ensure it returns the same result. It does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2de3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = df2['price'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc13393e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7160130346557048"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purity_entropy = -1 * np.sum(np.log2(freq) * freq)\n",
    "purity_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a37a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_impurity(feature, impurity_criterion):\n",
    "   \n",
    "    probs = feature.value_counts(normalize=True)\n",
    "    \n",
    "    if impurity_criterion == 'entropy':\n",
    "        impurity = -1 * np.sum(np.log2(probs) * probs)\n",
    "    elif impurity_criterion == 'gini':\n",
    "        impurity = 1 - np.sum(np.square(probs))\n",
    "    else:\n",
    "        raise ValueError('Unknown impurity criterion')\n",
    "        \n",
    "    return(round(impurity, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f23c232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.716"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purity_entropy_f = compute_impurity(df2['price'], 'entropy')\n",
    "purity_entropy_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e4cdf7",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "Determining the root node for decision tree.\n",
    "\n",
    "This code was written in from the course website and functions to provide an analysis of the levels in any given variable. In the example below the 'cut' variable is plugged in and the resulting tables return the data required to calculate the information gain of each variable, which is critical for determining the root node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a297924f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level name: Good\n",
      "corresponding data partition:\n",
      "      cut color       depth    price       carat\n",
      "0    Good     D  category_2      low  category_1\n",
      "2    Good     I  category_1      low  category_1\n",
      "3    Good     F  category_1      low  category_1\n",
      "6    Good     D  category_2      low  category_1\n",
      "7    Good     D  category_2      low  category_1\n",
      "..    ...   ...         ...      ...         ...\n",
      "202  Good     I  category_1  premium  category_3\n",
      "203  Good     I  category_1  premium  category_3\n",
      "205  Good     I  category_1  premium  category_3\n",
      "207  Good     F  category_2  premium  category_3\n",
      "210  Good     I  category_1  premium  category_3\n",
      "\n",
      "[152 rows x 5 columns]\n",
      "partition target feature impurity: 1.68\n",
      "partition weight: 152/212\n",
      "====================\n",
      "level name: Fair\n",
      "corresponding data partition:\n",
      "      cut color       depth    price       carat\n",
      "1    Fair     F  category_3      low  category_1\n",
      "4    Fair     F  category_3      low  category_1\n",
      "5    Fair     F  category_3      low  category_1\n",
      "9    Fair     F  category_3      low  category_1\n",
      "12   Fair     D  category_1      low  category_1\n",
      "13   Fair     F  category_1      low  category_1\n",
      "18   Fair     F  category_3      low  category_1\n",
      "20   Fair     F  category_1      low  category_1\n",
      "25   Fair     F  category_3      low  category_1\n",
      "27   Fair     I  category_1      low  category_2\n",
      "30   Fair     D  category_2      low  category_1\n",
      "31   Fair     D  category_3      low  category_1\n",
      "34   Fair     I  category_1      low  category_2\n",
      "42   Fair     I  category_1      low  category_2\n",
      "55   Fair     F  category_1      low  category_1\n",
      "68   Fair     I  category_3      low  category_2\n",
      "73   Fair     D  category_3      low  category_1\n",
      "79   Fair     F  category_1      low  category_1\n",
      "84   Fair     F  category_1      low  category_2\n",
      "85   Fair     I  category_3      low  category_2\n",
      "87   Fair     I  category_2      low  category_2\n",
      "89   Fair     F  category_1      low  category_2\n",
      "92   Fair     I  category_3      low  category_2\n",
      "97   Fair     F  category_1   medium  category_2\n",
      "101  Fair     I  category_3   medium  category_2\n",
      "106  Fair     I  category_3   medium  category_2\n",
      "119  Fair     I  category_3   medium  category_3\n",
      "121  Fair     D  category_1   medium  category_2\n",
      "122  Fair     F  category_3   medium  category_2\n",
      "124  Fair     I  category_3   medium  category_3\n",
      "125  Fair     D  category_3   medium  category_3\n",
      "127  Fair     F  category_3   medium  category_2\n",
      "130  Fair     F  category_3   medium  category_2\n",
      "131  Fair     I  category_1   medium  category_3\n",
      "132  Fair     D  category_3   medium  category_2\n",
      "133  Fair     I  category_3   medium  category_3\n",
      "138  Fair     D  category_3   medium  category_2\n",
      "139  Fair     F  category_3   medium  category_3\n",
      "142  Fair     F  category_3   medium  category_3\n",
      "143  Fair     I  category_3   medium  category_3\n",
      "147  Fair     F  category_1   medium  category_3\n",
      "149  Fair     F  category_3   medium  category_2\n",
      "150  Fair     F  category_3   medium  category_2\n",
      "157  Fair     F  category_1   medium  category_3\n",
      "161  Fair     D  category_1   medium  category_2\n",
      "165  Fair     I  category_3   medium  category_3\n",
      "169  Fair     I  category_3     high  category_3\n",
      "171  Fair     D  category_3     high  category_2\n",
      "178  Fair     I  category_1     high  category_3\n",
      "179  Fair     F  category_3     high  category_3\n",
      "180  Fair     I  category_1     high  category_3\n",
      "183  Fair     I  category_3     high  category_3\n",
      "184  Fair     I  category_3     high  category_3\n",
      "185  Fair     I  category_3     high  category_3\n",
      "199  Fair     I  category_3  premium  category_3\n",
      "204  Fair     F  category_3  premium  category_3\n",
      "206  Fair     F  category_3  premium  category_3\n",
      "208  Fair     D  category_1  premium  category_3\n",
      "209  Fair     F  category_3  premium  category_3\n",
      "211  Fair     F  category_1  premium  category_3\n",
      "partition target feature impurity: 1.78\n",
      "partition weight: 60/212\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "for level in df2['cut'].unique():\n",
    "    print('level name:', level)\n",
    "    df_feature_level = df2[df2['cut'] == level]\n",
    "    print('corresponding data partition:')\n",
    "    print(df_feature_level)\n",
    "    print('partition target feature impurity:', compute_impurity(df_feature_level['price'], 'entropy'))\n",
    "    print('partition weight:', str(len(df_feature_level)) + '/' + str(len(df2)))\n",
    "    print('====================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb8b1ac",
   "metadata": {},
   "source": [
    "This function returns the data needed to calculate the remainder, using the entropy split criterion, for the 'cut' feature.\n",
    "This is done by multiplying the target feature impurity of each level by their respective weights.\n",
    "\n",
    "1.68 x (152/212) + 1.78 x (60/212) = 1.708\n",
    "\n",
    "Information gain is calculated by deducting this number from the purity of the target feature.\n",
    "\n",
    "1.716 - 1.708 = 0.008\n",
    "\n",
    "This result is very poor for the variable 'cut' and signals that it would not be an optimal root node for the decision tree.\n",
    "\n",
    "Below is code (also from the course website) that creates a function that will apply these calculations to all the variables in our dataset and print out the relevant values, revealing the optimal node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "280ca8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_feature_information_gain(df, target, descriptive_feature, split_criterion):\n",
    "   \n",
    "    \n",
    "    print('target feature:', target)\n",
    "    print('descriptive_feature:', descriptive_feature)\n",
    "    print('split criterion:', split_criterion)\n",
    "            \n",
    "    target_entropy = compute_impurity(df[target], split_criterion)\n",
    "\n",
    "   \n",
    "    entropy_list = list()\n",
    "    weight_list = list()\n",
    "    \n",
    "   \n",
    "    for level in df[descriptive_feature].unique():\n",
    "        df_feature_level = df[df[descriptive_feature] == level]\n",
    "        entropy_level = compute_impurity(df_feature_level[target], split_criterion)\n",
    "        entropy_list.append(round(entropy_level, 3))\n",
    "        weight_level = len(df_feature_level) / len(df)\n",
    "        weight_list.append(round(weight_level, 3))\n",
    "\n",
    "    print('impurity of partitions:', entropy_list)\n",
    "    print('weights of partitions:', weight_list)\n",
    "\n",
    "    feature_remaining_impurity = np.sum(np.array(entropy_list) * np.array(weight_list))\n",
    "    print('remaining impurity:', feature_remaining_impurity)\n",
    "    \n",
    "    information_gain = target_entropy - feature_remaining_impurity\n",
    "    print('information gain:', information_gain)\n",
    "    \n",
    "    print('====================')\n",
    "\n",
    "    return(information_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf7e707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target feature: price\n",
      "descriptive_feature: cut\n",
      "split criterion: entropy\n",
      "impurity of partitions: [1.68, 1.78]\n",
      "weights of partitions: [0.717, 0.283]\n",
      "remaining impurity: 1.7083\n",
      "information gain: 0.00770000000000004\n",
      "====================\n",
      "target feature: price\n",
      "descriptive_feature: color\n",
      "split criterion: entropy\n",
      "impurity of partitions: [1.657, 1.445, 1.833]\n",
      "weights of partitions: [0.269, 0.434, 0.297]\n",
      "remaining impurity: 1.617264\n",
      "information gain: 0.09873599999999993\n",
      "====================\n",
      "target feature: price\n",
      "descriptive_feature: depth\n",
      "split criterion: entropy\n",
      "impurity of partitions: [1.517, 1.749, 1.74]\n",
      "weights of partitions: [0.349, 0.316, 0.335]\n",
      "remaining impurity: 1.6650170000000002\n",
      "information gain: 0.05098299999999978\n",
      "====================\n",
      "target feature: price\n",
      "descriptive_feature: carat\n",
      "split criterion: entropy\n",
      "impurity of partitions: [-0.0, 1.365, 1.529]\n",
      "weights of partitions: [0.335, 0.373, 0.292]\n",
      "remaining impurity: 0.9556129999999998\n",
      "information gain: 0.7603870000000001\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "split_criterion = 'entropy'\n",
    "for feature in df2.drop(columns='price').columns:\n",
    "    feature_info_gain = comp_feature_information_gain(df2, 'price', feature, split_criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8954c9b6",
   "metadata": {},
   "source": [
    "This table is populated with the results from above and indicates that 'carat' is the variable that splits into the more pure sets, or gains the most information. Therefore 'carat' should be the root node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bdbdb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>remainder</th>\n",
       "      <th>info_gain</th>\n",
       "      <th>is_optimal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cut</td>\n",
       "      <td>1.708</td>\n",
       "      <td>0.007</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>color</td>\n",
       "      <td>1.617</td>\n",
       "      <td>0.098</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depth</td>\n",
       "      <td>1.665</td>\n",
       "      <td>0.050</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carat</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.760</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split  remainder  info_gain is_optimal\n",
       "0    cut      1.708      0.007      False\n",
       "1  color      1.617      0.098      False\n",
       "2  depth      1.665      0.050      False\n",
       "3  carat      0.955      0.760       True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'split': ['cut', 'color', 'depth', 'carat'],\n",
    "        'remainder': [1.708, 1.617, 1.665,0.955],\n",
    "        'info_gain': [0.007, 0.098, 0.050, 0.760],\n",
    "        'is_optimal': ['False','False','False','True']}\n",
    "\n",
    "df_splits = pd.DataFrame(data)\n",
    "\n",
    "df_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3206c4db",
   "metadata": {},
   "source": [
    "### Part D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f71365",
   "metadata": {},
   "source": [
    "It is admitted that there is likely a more elegant solution, however the below satisfies the requirements of the table. The leaf_prediction column is made up of the category of price with the higest probability. \n",
    "\n",
    "To calculate the probability of each outcome for each category of 'carat' the frequency of each outcome was calculated from a data frame containing the relevant coloumns using the .value_counts function.\n",
    "\n",
    "These values were then added to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40e1ddfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carat       price\n",
      "category_1  low      1.0\n",
      "dtype: float64\n",
      "======================\n",
      "carat       price  \n",
      "category_2  medium     0.607595\n",
      "            low        0.278481\n",
      "            high       0.101266\n",
      "            premium    0.012658\n",
      "dtype: float64\n",
      "======================\n",
      "carat       price  \n",
      "category_3  medium     0.419355\n",
      "            high       0.370968\n",
      "            premium    0.209677\n",
      "dtype: float64\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "#To discover what the probability is of a level, within the carat variable, having a low_price, medium_price etc...  \n",
    "\n",
    "df_prob = df2[['carat', 'price']]\n",
    "\n",
    "A = df_prob[df_prob[\"carat\"].str.contains('category_1')].value_counts(normalize=True)\n",
    "print(A)\n",
    "print('======================')\n",
    "B = df_prob[df_prob[\"carat\"].str.contains('category_2')].value_counts(normalize=True)\n",
    "print(B)\n",
    "print('======================')\n",
    "C = df_prob[df_prob[\"carat\"].str.contains('category_3')].value_counts(normalize=True)\n",
    "print(C)\n",
    "print('======================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62978a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leaf_condition</th>\n",
       "      <th>low_price_prob</th>\n",
       "      <th>medium_price_prob</th>\n",
       "      <th>high_price_prob</th>\n",
       "      <th>premium_price_prob</th>\n",
       "      <th>leaf_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carat == category_1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>low_price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>carat == category_2</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.012</td>\n",
       "      <td>medium_price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>carat == category_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.209</td>\n",
       "      <td>medium_price</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        leaf_condition low_price_prob medium_price_prob high_price_prob  \\\n",
       "0  carat == category_1            1.0               0.0             0.0   \n",
       "1  carat == category_2          0.278             0.607           0.101   \n",
       "2  carat == category_3            0.0             0.419           0.370   \n",
       "\n",
       "  premium_price_prob leaf_prediction  \n",
       "0                0.0       low_price  \n",
       "1              0.012    medium_price  \n",
       "2              0.209    medium_price  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_b = {'leaf_condition': ['carat == category_1', 'carat == category_2', 'carat == category_3'],\n",
    "        'low_price_prob': ['1.0', '0.278', '0.0'],\n",
    "        'medium_price_prob': ['0.0', '0.607', '0.419'],\n",
    "        'high_price_prob': ['0.0','0.101','0.370'],\n",
    "        'premium_price_prob':['0.0', '0.012','0.209'],\n",
    "        'leaf_prediction':['low_price', 'medium_price', 'medium_price']}\n",
    "\n",
    "df_pred = pd.DataFrame(data_b)\n",
    "\n",
    "df_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
