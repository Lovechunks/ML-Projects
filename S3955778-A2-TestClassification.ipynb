{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Classification on Unseen Data (total 8 points)\n",
    "In this final task, you should read the feather file 'TestQuestionsDF.feather.zstd' into a pandas dataframe. Hereafter this will be referred to as the test_set. <br>You can assume that the test_set is a random sample from the same dataset as 'TrainQuestionsDF.feather.zstd' (hereafter train_set).\n",
    "Your goal is to classify the data in the test_set and achieve the best **average f1-score** using the train_set.\n",
    "You are allowed to utilize any technique and model available in the scikit-learn library or the standard python libraries to do so.\n",
    "Pay particular attention to the lessons learned from your experiments in the Classification notebook -- any of these approaches can be used to construct the model you use for prediction.\n",
    "You can additionally choose to generate and/or construct any features from the available data. Remember that the test_set should be represented with the same feature space as the train_set. <br>For example, features based on text should be constructed with the same vocabulary on the test_set as the train_set.<br>\n",
    "To achieve a high f1 score on unseen data, remember to utilize all the techniques you've learned in the lectures, lectorials and practicals.\n",
    "\n",
    "For this task, you are expected to submit the following:\n",
    "1. This notebook with your code, the code should be well documented and must run without errors.\n",
    "    There is no time limit, but it is a good practice to save the parameters of the best model and add an option to generate a model with those parameters. Without running the full tuning of the hyper-parameters. <br>\n",
    "2. Up to 4 prediction files, each predictions file will have exactly two columns: \"Id\" and \"Label\" with these headers and no other columns (e.g. index).<br>\n",
    " The file names should be SXXXXXXX-A2-predictions-\\<n\\>.csv - where n is a running integer {1,2,3,4}.\n",
    "\n",
    "Your mark in this task will depend on the following:\n",
    "1. The code is well documented, and the entire notebook runs without errors (1 points).\n",
    "2. The submitted solutions are reproducible, i.e. the submitted code can generate the submitted prediction files (2 points).\n",
    "3. The highest (out of the 4 prediction files) achieved average f1-score is in the following range:\n",
    " * (0.8, 1] (5 points)\n",
    " * (0.7, 0.8] (4 points)\n",
    " * (0.65, 0.7] (3 points)\n",
    " * (0, 0.65] (1 point)\n",
    "\n",
    "To support the reproducibility of your solution, use the random seed anywhere where the solution involves a random process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import io\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, GridSearchCV \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import feature_selection as fs\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Set the random seed as your student id (only numbers)\n",
    "RANDOM_SEED = 3955778\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_feather_to_df(feather_file_name):\n",
    "    \"\"\"\n",
    "    The function expects to receive a path to feather file,\n",
    "    it will read the file from the disk into a pandas dataframe\n",
    "    \"\"\"\n",
    "    return pd.read_feather(feather_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>Body</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>LastActivityDate</th>\n",
       "      <th>Title</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>FavoriteCount</th>\n",
       "      <th>LastEditorDisplayName</th>\n",
       "      <th>LastEditDate</th>\n",
       "      <th>LastEditorUserId</th>\n",
       "      <th>CommunityOwnedDate</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>OwnerDisplayName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>2010-07-19 19:12:57.157</td>\n",
       "      <td>31</td>\n",
       "      <td>30036</td>\n",
       "      <td>&lt;p&gt;In many different statistical methods there...</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-22 12:15:07.030</td>\n",
       "      <td>What is normality?</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>user88</td>\n",
       "      <td>2010-08-07 17:56:44.800</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>2010-07-19 19:28:34.220</td>\n",
       "      <td>13</td>\n",
       "      <td>1620</td>\n",
       "      <td>&lt;p&gt;Which methods are used for testing random v...</td>\n",
       "      <td>69</td>\n",
       "      <td>2011-05-12 18:38:27.547</td>\n",
       "      <td>Testing random variate generation algorithms</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>2010-08-25 14:12:54.547</td>\n",
       "      <td>919</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>298</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010-07-20 13:11:50.297</td>\n",
       "      <td>161</td>\n",
       "      <td>312967</td>\n",
       "      <td>&lt;p&gt;Am I looking for a better behaved distribut...</td>\n",
       "      <td>125</td>\n",
       "      <td>2016-09-21 15:41:29.603</td>\n",
       "      <td>In linear regression, when is it appropriate t...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>227</td>\n",
       "      <td>NA</td>\n",
       "      <td>2015-10-19 11:38:06.097</td>\n",
       "      <td>4253</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>956</td>\n",
       "      <td>2010-07-28 03:54:56.447</td>\n",
       "      <td>22</td>\n",
       "      <td>26750</td>\n",
       "      <td>&lt;p&gt;Given a list of p-values generated from ind...</td>\n",
       "      <td>520</td>\n",
       "      <td>2013-03-07 01:26:38.717</td>\n",
       "      <td>Multiple hypothesis testing correction with Be...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>NA</td>\n",
       "      <td>2010-08-12 16:07:55.730</td>\n",
       "      <td>520</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>1189</td>\n",
       "      <td>2010-07-28 08:15:51.733</td>\n",
       "      <td>5</td>\n",
       "      <td>919</td>\n",
       "      <td>&lt;p&gt;Here's something I've wondered about for a ...</td>\n",
       "      <td>34</td>\n",
       "      <td>2011-03-28 08:58:47.087</td>\n",
       "      <td>Series expansion of a density function</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>user88</td>\n",
       "      <td>2011-03-28 08:58:47.087</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  PostTypeId  AcceptedAnswerId            CreationDate  Score  \\\n",
       "0    2           1                59 2010-07-19 19:12:57.157     31   \n",
       "1   30           1                55 2010-07-19 19:28:34.220     13   \n",
       "2  298           1                -1 2010-07-20 13:11:50.297    161   \n",
       "3  870           1               956 2010-07-28 03:54:56.447     22   \n",
       "4  881           1              1189 2010-07-28 08:15:51.733      5   \n",
       "\n",
       "   ViewCount                                               Body  OwnerUserId  \\\n",
       "0      30036  <p>In many different statistical methods there...           24   \n",
       "1       1620  <p>Which methods are used for testing random v...           69   \n",
       "2     312967  <p>Am I looking for a better behaved distribut...          125   \n",
       "3      26750  <p>Given a list of p-values generated from ind...          520   \n",
       "4        919  <p>Here's something I've wondered about for a ...           34   \n",
       "\n",
       "         LastActivityDate                                              Title  \\\n",
       "0 2017-11-22 12:15:07.030                                 What is normality?   \n",
       "1 2011-05-12 18:38:27.547       Testing random variate generation algorithms   \n",
       "2 2016-09-21 15:41:29.603  In linear regression, when is it appropriate t...   \n",
       "3 2013-03-07 01:26:38.717  Multiple hypothesis testing correction with Be...   \n",
       "4 2011-03-28 08:58:47.087             Series expansion of a density function   \n",
       "\n",
       "   AnswerCount  CommentCount  FavoriteCount LastEditorDisplayName  \\\n",
       "0            7             1             11                user88   \n",
       "1            8             2             11                    NA   \n",
       "2            8             5            227                    NA   \n",
       "3            1             4             10                    NA   \n",
       "4            3             0              2                user88   \n",
       "\n",
       "             LastEditDate  LastEditorUserId CommunityOwnedDate  ParentId  \\\n",
       "0 2010-08-07 17:56:44.800                -1                NaT        -1   \n",
       "1 2010-08-25 14:12:54.547               919                NaT        -1   \n",
       "2 2015-10-19 11:38:06.097              4253                NaT        -1   \n",
       "3 2010-08-12 16:07:55.730               520                NaT        -1   \n",
       "4 2011-03-28 08:58:47.087                -1                NaT        -1   \n",
       "\n",
       "  ClosedDate OwnerDisplayName  \n",
       "0        NaT               NA  \n",
       "1        NaT               NA  \n",
       "2        NaT               NA  \n",
       "3        NaT               NA  \n",
       "4        NaT               NA  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = read_feather_to_df('TrainQuestionsDF.feather.zstd')\n",
    "test_df = read_feather_to_df('TestQuestionsDF.feather.zstd')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_numeric_non_id_columns(df):\n",
    "    \n",
    "    Z = (df.select_dtypes(include=['int64', 'object'], exclude=[\"string\", \"datetime64\"])).drop('Id',axis=1)\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = select_numeric_non_id_columns(train_df)\n",
    "\n",
    "Data = train_df.drop(columns = 'Label').values\n",
    "target = train_df['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope the use of a different algorithm might give me some luck so I'm going to use the probability based Naive Baise technique. Using my gridsearch function from before I look for the optimal hyperparameter (Var-Smoothing) and train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 100 candidates, totalling 1500 fits\n"
     ]
    }
   ],
   "source": [
    "cv_method = RepeatedStratifiedKFold(n_splits=5, \n",
    "                                    n_repeats=3, \n",
    "                                    random_state=RANDOM_SEED)\n",
    "\n",
    "\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "gs_NB = GridSearchCV(estimator=nb_classifier, \n",
    "                     param_grid=params_NB, \n",
    "                     cv=cv_method,\n",
    "                     verbose=1, \n",
    "                     scoring='accuracy')\n",
    "\n",
    "Data_transformed = PowerTransformer().fit_transform(Data)\n",
    "\n",
    "gs_NB.fit(Data_transformed, target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs_NB.best_params_)\n",
    "print(gs_NB.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = select_numeric_non_id_columns(test_df)\n",
    "\n",
    "print(set(gs_NB.predict(pred_data)))\n",
    "\n",
    "predictions_NB = gs_NB.predict(pred_data)\n",
    "test_df['Label'] = predictions_NB\n",
    "output_file = test_df[['Id', 'Label']]\n",
    "\n",
    "#pred_NB = pd.DataFrame(predictions_NB, columns = ['ID','Label'])\n",
    "\n",
    "predictions_NB                        \n",
    "#I tried lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file.to_csv('S3955778-A2-predictions-1.csv', mode='a', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
